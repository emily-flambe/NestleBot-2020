{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Nestle Product Images\n",
    "\n",
    "1. Extract product names from https://github.com/CharlesStover/peoplecott/blob/master/src/constants/children/children.ts\n",
    "\n",
    "2. Google image search [product]+' nestle food'\n",
    "\n",
    "### TODO:\n",
    "\n",
    "3. Choose a random image from the first page of results\n",
    "\n",
    "4. Tweet: \"Hello friends! Don't forget, [product] is a Nestle product! Nestle is an evil company. Don't buy it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_gis import google_image_search\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from detect_text import detect_text\n",
    "from get_twitter_api import get_twitter_api\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from os import environ\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the freshest data from Charles Stover's github repo (peoplecott)\n",
    "url='https://raw.githubusercontent.com/CharlesStover/peoplecott/master/src/constants/children/children.ts'\n",
    "brands_raw_file = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idk how .ts files work but we can use regex to extract the brand names from it\n",
    "\n",
    "#get horrible nasty raw list of all rows in the file that match any of the patterns\n",
    "re1 = re.compile(r'([A-Z]+)+:', re.IGNORECASE) #text before a semicolon\n",
    "re2 = re.compile(r'\"([^\"]*)\"', re.IGNORECASE)  #text between double quotes\n",
    "re3 = re.compile(r\"'([^']*)'\", re.IGNORECASE)  #text between single quotes\n",
    "raw_list = re.findall(re1, brands_raw_file)+re.findall(re2, brands_raw_file)+re.findall(re3, brands_raw_file)\n",
    "\n",
    "#clean up the riff-raff\n",
    "exclude_list = [\"http\",\"nestle\",\"\\\"\",\",\",\".\",\"parent\",\"source\",\"child\"]\n",
    "clean_list=[]\n",
    "for mystr in raw_list:\n",
    "    if all(x.upper() not in mystr.upper() for x in exclude_list):\n",
    "        clean_list.append(mystr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass all these product names into a bunch of google image search URLs\n",
    "\n",
    "#NOTE: ended up going a different way with this, but I'm keeping the code here for future reference\n",
    "\n",
    "#url_base = 'https://www.google.com/search?q=QUERY&source=lnms&tbm=isch'\n",
    "#image_search_queries = [x.replace(' ','+').replace('-','+').replace(\"'\",'')+'+nestle+food' for x in clean_list]\n",
    "#urls = [url_base.replace('QUERY',x) for x in image_search_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aero',\n",
       " 'Alpo',\n",
       " 'Arrowhead',\n",
       " 'Beba',\n",
       " 'Benecalorie',\n",
       " 'Benefiber',\n",
       " 'Beneful',\n",
       " 'Beneprotein',\n",
       " 'Bonka',\n",
       " 'Boost']"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting 5 images of Haagen-Dazs\n",
      "creating folder images/Haagen-Dazs...\n"
     ]
    }
   ],
   "source": [
    "# Choose a random item from the list\n",
    "index_to_use = random.randint(0,len(clean_list))\n",
    "item = clean_list[index_to_use]\n",
    "\n",
    "# Retrieve N google image results of that item\n",
    "num_images = 5\n",
    "print(f\"getting {num_images} images of {item}\")\n",
    "google_image_search(item, num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is False, continuing...\n",
      "Selected image images/Haagen-Dazs/Nestle-invests-in-Loop-launching-Haeagen-Dazs-in-a-reusable-container_wrbm_large.jpg - checking to make sure it includes text...\n",
      "Image contains text, good for the tweetening.\n"
     ]
    }
   ],
   "source": [
    "# Randomly select one of the remaining images\n",
    "# Check to make sure the image contains text. If it does not, delete the file and try again\n",
    "\n",
    "image_dir=f\"images/{item}\"\n",
    "image_files = glob.glob(f\"{image_dir}/*\")\n",
    "\n",
    "x=False\n",
    "\n",
    "while x==False:\n",
    "    print(f\"X is {x}, continuing...\")\n",
    "    image_file_index_to_use=random.randint(0,len(image_files))\n",
    "    tweet_image_path=image_files[image_file_index_to_use]\n",
    "    print(f\"Selected image {tweet_image_path} - checking to make sure it includes text...\")\n",
    "    if detect_text(tweet_image_path)==True:\n",
    "        print(f\"Image contains text, good for the tweetening.\")\n",
    "        x=True\n",
    "    else:   \n",
    "        os.remove(tweet_image_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tweet the image!\n",
    "print(\"getting Twitter API\")\n",
    "api = get_twitter_api()\n",
    "\n",
    "# Upload image to Twitter\n",
    "print(f\"uploading {tweet_image_path} to Twitterspace\")\n",
    "media = api.media_upload(tweet_image_path)\n",
    "\n",
    "# Post tweet with image\n",
    "print(\"Tweeting!\")\n",
    "randint = random.randint(1,1000000)\n",
    "tweet = f\"Have you heard about {item}? It's a bullshit product by the bullshit company Nestle. Reminder #{randint} not to purchase this. Thanksx\"\n",
    "post_result = api.update_status(status=tweet, media_ids=[media.media_id])\n",
    "\n",
    "print(\"Tweeted!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use requests package to download image from search results\n",
    "# (random Nth result between 1 and 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
